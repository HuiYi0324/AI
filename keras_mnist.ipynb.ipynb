{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ro4I6VMN1kbH"
      },
      "outputs": [],
      "source": [
        "# 匯入 Keras 模組\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "\n",
        "# -----------------------------\n",
        "# 建立一個序列式 (Sequential) 模型\n",
        "# -----------------------------\n",
        "model = Sequential()\n",
        "\n",
        "# -----------------------------\n",
        "# 模型結構設計\n",
        "# -----------------------------\n",
        "\n",
        "# 1️⃣ Flatten層：將輸入的多維陣列攤平成一維向量\n",
        "#   假設輸入是 28x28 的圖片 (例如MNIST)，\n",
        "#   攤平成 784 維的向量以供全連接層(Dense layer)使用\n",
        "model.add(Flatten())\n",
        "\n",
        "# 2️⃣ 第一層全連接層 (Dense layer)\n",
        "#   - 有 32 個神經元\n",
        "#   - 使用 ReLU 激活函數\n",
        "#   - 指定輸入維度為 784 (對應 28x28 圖片)\n",
        "model.add(Dense(32, activation='relu', input_dim=784))\n",
        "\n",
        "# 3️⃣ 第二層全連接層\n",
        "#   - 32 個神經元\n",
        "#   - 使用 ReLU 激活函數\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# 4️⃣ 輸出層 (Output layer)\n",
        "#   - 10 個神經元（對應 0~9 的分類）\n",
        "#   - 使用 sigmoid 激活函數（建議分類問題可改為 softmax）\n",
        "model.add(Dense(10, activation='sigmoid'))\n",
        "\n",
        "# -----------------------------\n",
        "# 編譯模型\n",
        "# -----------------------------\n",
        "# - 優化器：RMSProp（自動調整學習率的常見選擇）\n",
        "# - 損失函數：sparse_categorical_crossentropy\n",
        "#   → 用於整數標籤的多分類問題（例如 y=[0,1,2,...,9]）\n",
        "# - 評估指標：accuracy（正確率）\n",
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist=keras.datasets.mnist\n",
        "(train_data, train_label), (test_data, test_label) = mnist.load_data()"
      ],
      "metadata": {
        "id": "muiYffSX_hSM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 印出訓練資料 (train_data) 的型態\n",
        "# 通常會是 numpy.ndarray，表示資料是以陣列形式儲存\n",
        "print(type(train_data))\n",
        "\n",
        "# 印出訓練資料的維度（形狀）\n",
        "# 例如 (60000, 28, 28) 表示共有 6 萬張 28x28 的影像\n",
        "print(train_data.shape)\n",
        "\n",
        "# 印出訓練標籤 (train_label) 的型態\n",
        "# 一般來說也是 numpy.ndarray\n",
        "print(type(train_label))\n",
        "\n",
        "# 印出訓練標籤的維度\n",
        "# 例如 (60000,) 表示有 6 萬個對應的標籤（每張圖一個數字）\n",
        "print(train_label.shape)\n",
        "\n",
        "# 印出測試資料 (test_data) 的維度\n",
        "# 例如 (10000, 28, 28)，表示有 1 萬張 28x28 的影像作為測試集\n",
        "print(test_data.shape)\n",
        "\n",
        "# 印出測試標籤 (test_label) 的維度\n",
        "# 例如 (10000,)，代表有 1 萬個標籤對應測試集\n",
        "print(test_label.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXMSIOcU_lAk",
        "outputId": "bce1b460-a947-43af-af85-5322d63fe0ef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(60000, 28, 28)\n",
            "<class 'numpy.ndarray'>\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 印出訓練資料集中「第一筆影像」對應的標籤 (label)\n",
        "# 這個標籤代表這張圖片是什麼數字（例如 5、7、9 等）\n",
        "# 若使用的是 MNIST 資料集，結果會是一個整數，例如：\n",
        "# >>> print(train_label[0])\n",
        "# 5\n",
        "print(train_label[0])\n",
        "\n",
        "# 印出訓練資料集中「第一張圖片」的像素資料\n",
        "# 這會是一個 28x28 的矩陣 (numpy 陣列)\n",
        "# 每個數值代表該像素的灰階強度 (0~255)\n",
        "# 通常這張圖對應到上面那個標籤（例如數字 5 的圖片）\n",
        "# >>> print(train_data[0])\n",
        "# [[  0   0   0  ...  0]\n",
        "#  [  0   0   0  ...  0]\n",
        "#  ...\n",
        "#  [  0   0   0  ...  0]]\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qji4nJlJ_pbc",
        "outputId": "d426ca08-46a0-435b-abe6-1211123a401d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 匯入 matplotlib.pyplot 模組，用於繪圖\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 使用 imshow() 顯示 train_data 中的第一張圖片 (索引 0)\n",
        "# - cmap='binary' 表示使用黑白色階顯示（黑白反差明顯）\n",
        "#   0 → 黑色，255 → 白色\n",
        "# - train_data[0] 是一個 28x28 的矩陣，每個數值代表灰階像素強度\n",
        "plt.imshow(train_data[0], cmap='binary')\n",
        "\n",
        "# 顯示圖像\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "tghTO_Fa_vKr",
        "outputId": "e43e8859-8ab0-446d-8805-3ac6193e6461"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 匯入 Keras 模組\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "\n",
        "# -----------------------------\n",
        "# 建立序列式模型 (Sequential Model)\n",
        "# -----------------------------\n",
        "model = Sequential()\n",
        "\n",
        "# -----------------------------\n",
        "# 模型結構設計\n",
        "# -----------------------------\n",
        "\n",
        "# 1️⃣ Flatten 層：\n",
        "# 將輸入資料攤平成一維向量\n",
        "# 假設輸入是 28x28 的圖片，會攤平成 784 維\n",
        "model.add(Flatten())\n",
        "\n",
        "# 2️⃣ 第一層全連接層 (Dense layer)\n",
        "# - 有 32 個神經元\n",
        "# - 使用 ReLU 激活函數\n",
        "# - input_dim=784 指定輸入維度（對應 Flatten 後的向量長度）\n",
        "model.add(Dense(32, activation='relu', input_dim=784))\n",
        "\n",
        "# 3️⃣ 輸出層 (Output layer)\n",
        "# - 10 個神經元（對應 0~9 的分類）\n",
        "# - 使用 sigmoid 激活函數（建議多分類問題使用 softmax 會更合適）\n",
        "model.add(Dense(10, activation='sigmoid'))\n",
        "\n",
        "# -----------------------------\n",
        "# 編譯模型\n",
        "# -----------------------------\n",
        "# - optimizer='rmsprop'：使用 RMSProp 優化器\n",
        "# - loss='sparse_categorical_crossentropy'：適用於整數標籤的多分類問題\n",
        "# - metrics=['accuracy']：評估指標為準確率\n",
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "DyHxSbYv_zT-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 訓練模型\n",
        "# -----------------------------\n",
        "# model.fit() 用來進行模型訓練\n",
        "# 參數說明：\n",
        "# - train_data: 訓練資料 (輸入特徵)\n",
        "# - train_label: 訓練標籤 (輸入標籤)\n",
        "# - epochs=20: 訓練 20 個完整週期 (遍歷整個訓練集 20 次)\n",
        "# - batch_size=512: 每次梯度更新使用 512 筆資料 (mini-batch)\n",
        "model.fit(train_data, train_label, epochs=20, batch_size=512)\n",
        "\n",
        "# -----------------------------\n",
        "# 評估模型在測試集上的表現\n",
        "# -----------------------------\n",
        "# model.evaluate() 會回傳 [loss, accuracy]（依 compile 設定的 metrics）\n",
        "# - test_data: 測試資料\n",
        "# - test_label: 測試標籤\n",
        "score = model.evaluate(test_data, test_label)\n",
        "\n",
        "# 印出模型在測試集上的準確率 (accuracy)\n",
        "# score[0] → loss 值\n",
        "# score[1] → accuracy\n",
        "print(score[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOfqnBQS_4Ez",
        "outputId": "3801c07f-e982-40f9-c5d4-39593a883115"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3575 - loss: 31.7747\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5191 - loss: 1.1332\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5381 - loss: 0.7542\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5301 - loss: 0.6239\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5113 - loss: 0.4937\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5016 - loss: 0.4140\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4995 - loss: 0.3682\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4989 - loss: 0.3411\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4944 - loss: 0.3068\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5033 - loss: 0.2756\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5042 - loss: 0.2630\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5036 - loss: 0.2423\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5111 - loss: 0.2340\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5095 - loss: 0.2213\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5131 - loss: 0.2190\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5028 - loss: 0.2047\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5065 - loss: 0.2054\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5164 - loss: 0.1974\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5076 - loss: 0.1877\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5120 - loss: 0.1767\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5042 - loss: 0.3290\n",
            "0.5066999793052673\n"
          ]
        }
      ]
    }
  ]
}